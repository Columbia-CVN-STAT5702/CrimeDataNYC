---
title: "New York City and Crime, A Story of Data Analysis "
### STATGR5702 Spring 2018 Final Project
author: Brent Daniel, Richard Lavery, Anita Pinto, Rashmi Rajaguru, Jingbo Wu
due date: April 26, 2018
output: html_document
---

 
```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE,
                      echo=TRUE,
                      message = FALSE, 
                      cache = TRUE)
```



```{r echo=FALSE}
library(zoo)
library(vcd)
library(dplyr)
library(tidyr)
library(tibble)
library(lattice)
library(ggplot2)
library(forcats)
library(extracat)
library(vcdExtra)
library(gridExtra)
library(tidyverse)
library(data.table)
```


## Introduction

Crime has long been a story in New York City. Many of us have witnessed significant changes in both the frequency of crime and the most prevalent types of crime that have dominated New York City in the last 30 years.

Crime, in general, is a major topic for any major city. Whatever a city may have to offer, crime seems to be a major detractor for those visiting and considering living there. 

It is only natural, then, we should want to give crime in New York a thorough, analytical look.


* **What** crimes are happening? (What types of crime are most frequent?)
* **Where** do crimes happen? (Which Boroughs? Maps of crime?)
* **When** do crimes occur? (Time of day? Of Month? How has crime changed over time?) 
* **Why?** (Or, what other phenomena might explain crime frequency?)

(It is unsurprising that we cannot examine **Who** and **How**, as public datasets protect perpetrator and victim privacy, and don’t include methods of crime).

Our analysis will focus on exploration of these themes, the **What**, **Where**, **When** and **Why** of New York City Crime.  

Team Members and main roles:  

* Brent Daniel: Borough Crime Analysis, Crime vs. Temperature, Writing/Editing, Project Leadership
* Rich Lavery: Merging Meteorological and Lunar Cycle Data Looking for Relationships with Crime.  Interactive Web Application Development.  
* Anita  Pinto: Offense Categories Broad and Internal Desc with Borough Distribution, Premises/Location Analysis for Different Crime Categories, Crimes in Parks and Categories, Time Trend of Crime Categories and Attempted Crime Analysis 
* Rashmi Rajaguru:  Interactive Web Application development and D3 plot ,Project Data and deployment summary and challenges , Spatial Data analysis , Word Cloud based crime description (Interactive ) 
* Jingbo Wu:  Data description; Data Quality Analysis; Partial Main Analysis including time series, frequency analysis on different time scale (annual cycle, monthly cycle, weekly cycle, daily cycle); heatmaps; frequency by Precincts   


## Description of Data 

#### Main Data Set

The main source of data is from the New York City Open Data site, and can be accessed as follows:  
1. Visit https://data.cityofnewyork.us/Public-Safety/NYPD-Complaint-Data-Historic/qgea-i56i  
2. Click Export  
3. Click CSV button  
4. Put it in your working directory  


We downloaded the data for our own analysis on March 5, 2018. The data is updated annually in August, though it would be possible to replicate this analysis after August by limiting the data by date to the same time frame.

* This dataset includes all valid felony, misdemeanor, and violation crimes reported to the New York City Police Department (NYPD) from 2006 to the end of the year prior to the dataset creation (2016). The dataset was created on November 2, 2017. 
* The dataset is provided by The New York Police Department and owned by NYC OpenData. It has 5.58 Million rows and 24 variables. Three types of variables included are number, text, and location. The 24 variables are listed below. 
* Only valid complaints are included in this release. Information is accurate as of the date it was queried from the system of the record, but should be considered a close approximation of the current records, due to complaint revisions and updates. (NYPDIncidentLevelDataFootnotes.pdf)  


We used the following commands to import and arrange the data for analysis:

```{r results ="hide"}
var_names <- c("Id", "DateStart", "TimeStart", "DateEnd", "TimeEnd", "DateReport", "ClassCode", "OffenseDesc", 
               "IntClassCode", "IntOffenseDesc", "AtptCptdStatus", "Level", "Jurisdiction", "Boro", "Pct", "LocOfOccr", "PremDesc", "ParkName", "HousingDevName", "XCoord", "YCoord", "Lat", "Long", "Lat_Long")

crime_df <- fread("NYPD_Complaint_Data_Historic.csv",na.strings="", col.names = var_names, stringsAsFactors = TRUE)

crime_df <- crime_df %>% 
                mutate(DateStart=as.Date(DateStart,format='%m/%d/%Y'),
                      DateEnd=as.Date(DateEnd,format='%m/%d/%Y'),
                      DateReport=as.Date(DateReport,format='%m/%d/%Y'))
```

#### Supplementary Data Sets

To examine relationships with crime that went beyond the main data set, we accessed the following, other sites:  

* Borough Population Data  
http://www1.nyc.gov/site/planning/data-maps/nyc-population/current-future-populations.page

* Phases of the Moon Data  
https://www.somacon.com/p570.php

* Police Precinct Map Data  
https://data.cityofnewyork.us/Public-Safety/Police-Precincts/78dh-3ptz/data

* Weather Data  
https://www.ncdc.noaa.gov/



## Analysis of Data Quality

We found no significant issues in data quality that would inhibit analysis, with the possible exception of geo-location pertaining to certain types of crimes.

The dataset has 24 variables and approximately 5.6 million rows, each listing a single complaint or event. The Report Date (the case reporting time) ranges from 2006-01-01 to 2016-12-31. In this section, we will investigate the patterns of missing data as well as potential errors in the data in order to determine how well we can trust the data we are using.


#### Missing variables Pattern using Visna

A summary graphic of missing patterns is shown below  


```{r fig.height=6}
visna(crime_df,sort="b")
``` 

From the above Visna Plot, our observations about the missing patterns are as below :  

* Five of the 24 variables have no data quality concerns:
    1. Complaint Number  
    2. Report Date  
    3. Offense Classification Code  
    4. Level of Offense  
    5. Jurisdiction responsible  
* *AtptCptdStatus* is an indicator of whether crime attempted or completed. There are only 7 missing cases; 5,483,869 coded as completed, and 96,159 cases indicated as attempted.  
* *ParkName* is recorded if the event occurred in a park. Most of the cases doesn’t have this variable simply because most crimes did not occur in parks. We cannot estimate the percent of real missing park data.  



#### Missing Start-Date of Crime Reported

```{r}
#get the reporting dates of cases with starting dates missing and histogram over DateReport
crime_df%>%select(DateStart,DateReport)%>%filter(is.na(DateStart))%>%select(DateReport)->tmp1
ggplot(tmp1,aes(DateReport))+ geom_histogram(bins=120)->p1

#compare pattern of crime Level between all cases vs. cases with missing DateStart
crime_df%>%select(DateStart,Level)%>%filter(is.na(DateStart))%>%select(Level)%>%group_by(Level)%>%dplyr::summarise(count=n())%>%mutate(RelFreq = count/sum(count))->tmp3; nr1=nrow(tmp3)
tmp3%>%mutate(type=replicate(nr1,"DateStart_NA"))->tmp3
crime_df%>%select(Level)%>%group_by(Level)%>%dplyr::summarise(count=n())%>%mutate(RelFreq = count/sum(count))->tmp5; nr2=nrow(tmp5)
tmp5%>%mutate(type=replicate(nr2,"All"))->tmp5
rbind(tmp3,tmp5)->tmp3tmp5
tmp3tmp5%>%ggplot(aes(Level,RelFreq))+geom_bar(stat="identity")+scale_x_discrete(label=abbreviate)+
  coord_flip()+xlab("Level of Offense")+ylab("Relative Frequency")+facet_wrap(~type)->p2

#compare pattern of ClassCode between all cases vs. cases with missing DateStart
crime_df%>%select(DateStart,ClassCode)%>%filter(is.na(DateStart))%>%select(ClassCode)%>%mutate(ClassCode=as.factor(ClassCode))%>%group_by(ClassCode)%>%dplyr::summarise(count=n())%>%mutate(RelFreq = count/sum(count))->tmp2; nrr1=nrow(tmp2)
tmp2%>%mutate(type=replicate(nrr1,"DateStart_NA"))->tmp2
crime_df%>%select(ClassCode)%>%mutate(ClassCode=as.factor(ClassCode))%>%group_by(ClassCode)%>%dplyr::summarise(count=n())%>%mutate(RelFreq = count/sum(count))->tmp4; nrr2=nrow(tmp4)
tmp4%>%mutate(type=replicate(nrr2,"All"))->tmp4
rbind(tmp2,tmp4)->tmp2tmp4
tmp2tmp4%>%ggplot(aes(ClassCode,RelFreq),na.rm=FALSE)+geom_bar(stat="identity")+theme(text = element_text(size=5))+
  coord_flip()+xlab("Offense Classification Code")+ylab("Relative Frequency")+facet_wrap(~type)->p3

grid.arrange(p1,p2,p3,nrow=1)
```


There are total of 655 complaints missing the crime Start Date. The missing data is distributed the same as non-missing data, so we are not concerned about this random-appearing missing data.

When looking at the Date of the Report against the volume of missing Start Dates, we notice that the are far more missing Start Dates in the earlier time periods with the volume of missing leveling out after 2010.
The frequency of missing Start Date by Level of Crime looks the same as the non-missing Start Date data.
The frequency distribution of the Offense Code shares the same pattern as the non-missing Start Date data.

#### Errors in Start-Date of Crime Reported

```{r fig.height=4,fig.width=4}
crime_df%>%select(DateStart,DateEnd,DateReport)->df_3DT
df_3DT%>%filter(DateStart<=as.Date("1900-01-01"))->df_3DT_Year1900  
df_3DT%>%filter(DateStart>=as.Date("1900-01-01") & DateStart<=as.Date("1920-01-01"))->df_3DT_Year1900to1920
df_3DT%>%filter(DateStart>=as.Date("1920-01-01") & DateStart<=as.Date("1960-01-01"))->df_3DT_Year1920to1960
df_3DT%>%filter(DateStart>=as.Date("1960-01-01") & DateStart<=as.Date("1980-01-01"))->df_3DT_Year1960to1980
#association between report date and complaint date indicating possible typo in recording the data
splom(df_3DT_Year1900,varname.cex = .5,axis.text.cex = 0.5,cex=.5,xlab=NULL)->pl1
splom(df_3DT_Year1900to1920,varname.cex = .5,axis.text.cex = .5,cex=.5,xlab=NULL)->pl2
splom(df_3DT_Year1920to1960,varname.cex = .5,axis.text.cex = .5,cex=.5,xlab=NULL)->pl3
splom(df_3DT_Year1960to1980,varname.cex = .5,axis.text.cex = .5,cex=.5,xlab=NULL)->pl4
grid.arrange(pl1,pl2,pl3,pl4,nrow=2)
```

* There seems to be errors in *DateStart*. Some cases are shown with a year of 1015 (needless to say, a time frame not covered by this dataset). By comparing those Start Dates to the Dates of the Report, The two dates usually have very close month/date. The *DateEnd* variable also suggests the actual year to be 2015, and hence, a typo.   
* The scatterplot of *DateStart* vs *DateReport* did show some strict linear correlation for many cases during some periods.
* As shown in the figure, the amount of such cases is very small. In our main analysis, we will focus on cases with *DateStart* after Jan. 1, 2000 up until Dec. 31, 2016 in total over 5.57M. Cases with *DateStart* earlier than Jan. 1, 2000 are totaled 1549 which will be ignored.



#### Missing Premises Description *(PremDesc)*

```{r}
#get the reporting dates of cases with PremDesc missing and histogram over DateReport
#crime_df%>%filter(is.na(PremDesc))%>%dplyr::summarise(count=n()) #35198 missing cases
crime_df%>%select(PremDesc,DateReport)%>%filter(is.na(PremDesc))%>%select(DateReport)->tmp1
ggplot(tmp1,aes(DateReport))+ geom_histogram(bins=120)->p1

#compare pattern of crime Level between all cases vs. cases with missing PremDesc
crime_df%>%select(PremDesc,Level)%>%filter(is.na(PremDesc))%>%select(Level)%>%group_by(Level)%>%dplyr::summarise(count=n())%>%mutate(RelFreq = count/sum(count))->tmp3; nr1=nrow(tmp3)
tmp3%>%mutate(type=replicate(nr1,"PremDesc_NA"))->tmp3
crime_df%>%select(Level)%>%group_by(Level)%>%dplyr::summarise(count=n())%>%mutate(RelFreq = count/sum(count))->tmp5; nr2=nrow(tmp5)
tmp5%>%mutate(type=replicate(nr2,"All"))->tmp5
rbind(tmp3,tmp5)->tmp3tmp5
tmp3tmp5%>%ggplot(aes(Level,RelFreq))+geom_bar(stat="identity")+scale_x_discrete(label=abbreviate)+
  coord_flip()+xlab("Level of Offense")+ylab("Relative Frequency")+facet_wrap(~type)->p2

#compare pattern of ClassCode between all cases vs. cases with missing PremDesc
crime_df%>%select(PremDesc,ClassCode)%>%filter(is.na(PremDesc))%>%select(ClassCode)%>%mutate(ClassCode=as.factor(ClassCode))%>%group_by(ClassCode)%>%dplyr::summarise(count=n())%>%mutate(RelFreq = count/sum(count))->tmp2; nrr1=nrow(tmp2)
tmp2%>%mutate(type=replicate(nrr1,"PremDesc_NA"))->tmp2
crime_df%>%select(ClassCode)%>%mutate(ClassCode=as.factor(ClassCode))%>%group_by(ClassCode)%>%dplyr::summarise(count=n())%>%mutate(RelFreq = count/sum(count))->tmp4; nrr2=nrow(tmp4)
tmp4%>%mutate(type=replicate(nrr2,"All"))->tmp4
rbind(tmp2,tmp4)->tmp2tmp4
tmp2tmp4%>%ggplot(aes(ClassCode,RelFreq),na.rm=FALSE)+geom_bar(stat="identity")+theme(text = element_text(size=10))+
  coord_flip()+xlab("Offense Classification Code")+ylab("Relative Frequency")+facet_wrap(~type)->p3

grid.arrange(p1,p2,p3,nrow=1)
```

We do not rely on the description of premises much in our analyses, but readers should note that approximately 0.6% of the crimes do not have a description of the premises, with a disproportionately high number of those cases pertaining to murder/manslaughter.

* There are 35,198 cases missing the description of the premises.
* Comparison of the pattern of ClassCode between all cases vs. cases with missing PremDesc indicates that the category with ClassCode=101, which represents felony crime of MURDER & NON-NEGL. MANSLAUGHTER, have much higher frequency in the missing data.
* In 2006, there are many more cases with missing PremDesc than other years. Year 2006 had more cases overall compared to other years.


#### Mismatch between Precinct *(Pct)* and Borough *(Boro)*

```{r}
crime_df %>% select(Pct,Boro)%>%group_by(Pct,Boro)%>%drop_na()%>%dplyr::summarise(count=n())->tmp1
uniPct<-unique(tmp1$Pct)
for (i in  1:length(uniPct)) {
  if(nrow(tmp1%>%filter(Pct==(uniPct)[i])) > 1){
    print(tmp1%>%filter(Pct==(uniPct)[i]))
  }
}
```


There are a very small number of cases where Precinct or Borough are missing (0.007% and 0.008% of all cases, respectively). There is an even smaller number of cases where the Precinct shows an incorrect Borough.

* There are total of 77 distinct police precincts in NYC. A list above shows cases where a Borough is listed for a Precinct that is inconsistent with the vast majority of cases.
* There are about 16 cases where the Precinct shown is not consistent with the Borough in this manner. For those Precincts with such inconsistencies, the number of cases with a inconsistent Borough name range from 1 to 3 cases. This problem can be fixed by correcting the Borough names of those rare cases using a map of Pct vs Boro established from dataset.
* 390 cases have a missing Pct. 463 cases have a missing Boro. 

** This section below needs review, did not find in word,  I see that we are using this to correct and merge, so should we move to appropriate section **  
\
\
```{r}
#match_pct_boro can be used to fix the problem of double/triple borough names of specific Pct
crime_df %>% select(Pct,Boro)%>%group_by(Pct,Boro)%>%drop_na()%>%dplyr::summarise(count=n())%>%
  group_by(Pct)%>%dplyr::summarise(Boro=Boro[count==max(count)])->match_pct_boro

#It takes time to merge onto crime_df to have Pct and Boro have 1-to-1 correspondense (so I commented out). 
#Another way is to perform merge after you have manipulted your data into a small array, i.e. only merge when needed; so you can
#replace "crime_df%>%select(-Boro)" in the line below with whatever datatable you have to match Pct with Boro, 
#and replace "crime_df" with any new datatable you want to create
#merge(crime_df%>%select(-Boro),match_pct_boro, by.x="Pct",by.y = "Pct",all.x=TRUE)->crime_df
```


#### Missing Description of Offense *(OffenseDesc)*
 

```{r}
#match_code_desc can be used to retrieve OffenseDesc(when missing) from ClassCode
crime_df%>%select(ClassCode,OffenseDesc)%>%group_by(ClassCode)%>%
  dplyr::summarise(OffenseDesc=paste(unique(OffenseDesc),collapse=","))%>%
  mutate(OffenseDesc=str_replace(OffenseDesc,",NA",""))%>%mutate(OffenseDesc=str_replace(OffenseDesc,"NA,",""))->match_code_desc

#For cases with missing OffenseDesc, how they distribute over the code ClassCode
crime_df%>%
  select(ClassCode,OffenseDesc)%>%
  filter(is.na(OffenseDesc))%>%
  group_by(ClassCode)%>%dplyr::summarise(count=n())->tmp1

#showing the supposed OffenseDesc that is missing with its ClassCode
merge(tmp1,match_code_desc,by.x="ClassCode",by.y="ClassCode")%>%arrange(dplyr::desc(count))->match_bycount

par(mgp=c(1,0.3,0),mai=c(0.4,1.8,0.01,0.01))
data2<-match_bycount[order(match_bycount[,"count"]),]
barplot(data2[,"count"],names.arg=abbreviate(data2[,"OffenseDesc"],minlength=20),cex.names = 0.6,cex.axis=0.7,cex.lab=0.8,horiz=TRUE,xlim=c(0,17500),las=1,xlab="Count")

#Again, merging is commented out, perform it when needed
#merge(crime_df%>%select(-OffenseDesc),match_code_desc, by.x="ClassCode",by.y = "ClassCode",all.x=TRUE)->crime_df
```

Since the description of the offense can be inferred from the classification code, we should not be concerned about the missing values in this variable. 

* *OffenseDesc* (with missing values) is the description of offense corresponding with key code ClassCode (which is complete in the dataset). Code and description map to each other and a valid *OffenseDesc* can be inferred from a map established from the dataset.
The plot above shows missing counts of the ClassCode categories with *OffenseDesc* originally missing but now retrieved from the map between *ClassCode* and *OffenseDesc*.
* *OffenseDesc* (with missing values) is the description of offense corresponding with key code *ClassCode* which is complete in the dataset. Code and description map each other and valid *OffenseDesc* can be infered from a map established from the dataset.  
* The plot above shows missing counts of the *ClassCode* categories with *OffenseDesc* originally missing but now retrieved from the map between *ClassCode* and *OffenseDesc*.

#### Missing Geolocation

```{r}
#For cases with missing geolocation (using Lat here), how they distribute over the code ClassCode
crime_df%>%
  select(ClassCode,Lat)%>%
  filter(is.na(Lat))%>%
  group_by(ClassCode)%>%dplyr::summarise(count=n())->tmp1

merge(tmp1,match_code_desc,by.x="ClassCode",by.y="ClassCode")%>%arrange(desc(count))->match_bycount

#par(mar=c(4.1,15.1,2.1,2.1))
par(mgp=c(1,0.2,0),mai=c(0.4,2.5,0.01,0.5))
data2<-match_bycount[order(match_bycount[,"count"]),]
barplot(data2[,"count"],names.arg=abbreviate(data2[,"OffenseDesc"],minlength=20),horiz=TRUE,cex.names = 0.4,cex.axis=0.7,cex.lab=0.8,xlim=c(0,50000),las=1,xlab="Count")
```
\
\
* The 5 geolocation variables have the same missing pattern as expected. So we only need to look at one of them to examine the missing. In the data document, it stated that "to protect victim identities, rape and sex crime offenses are not geocoded". We want to see if the missing of geo variables are mostly related with those crime? Is there a lot of missing for other crimes too?

* The missing in geolocation is obviously not random. When examine the spatial pattern of the crimes, we have to bear in mind that particular crimes will not appear on the map due to missing not at random. 


# 4. Main Analysis 
```{r}
crime_df%>%select(DateReport)%>%mutate(Year=year(DateReport))%>%group_by(Year)%>%dplyr::summarise(Report=n())->totalCntByRD
crime_df%>%select(DateStart)%>%mutate(Year=year(DateStart))%>%filter(Year>=2000)%>%group_by(Year)%>%dplyr::summarise(Start=n())->totalCntBySD

cbind(rbind(data.frame(Year=2000:2005,Report=NA),totalCntByRD),
      totalCntBySD[,2])%>%gather(key,value=count,-Year)->totalCnt
ggplot(totalCnt)+geom_point(aes(count,Year,color=key),size=5)+coord_flip()+theme(legend.title=element_blank())->p1
totalCnt%>%filter(Year>=2006)%>%ggplot()+geom_point(aes(count,Year,color=key),size=5)+coord_flip()+ylim(2006,2016)+theme(legend.title=element_blank())->p2
grid.arrange(p1,p2)
```


* The total frequency over each year has a trend of declining. This may be due to lots of cases occurred over the years haven't been reported yet. It makes sense the later the more cases expected to be reported. But doesnt seem to explain the big decreasing in # of cases reported over the year. Most likely the crime is decreasing over the year!!
* The big difference between Start and Report in Year 2016 again mostly like is because a lot of cases occurred in Year 2016 haven't been able to be presented in this figure due to span of DateReport cut off at Dec. 31,2016. 
* Number of Cases with DateStart earlier than Jan. 1, 2000 are very small.
\
\
```{r}
#picking non-missing DateStart and filter only those after "2000-01-01", 5560408 obs.
crime_df%>%select(DateStart,Level)%>%filter(!is.na(DateStart))%>%filter(DateStart>=as.Date("2000-01-01"))->df_Date
```

```{r}
#time series of daily frequency of 3 crime categories 2006-2016
df_Date%>%group_by(DateStart,Level)%>%dplyr::summarise(count=n())%>%ungroup()%>%group_by(Level)%>%mutate(mon_mean=rollmean(count,30,fill=NA))%>%ungroup()->byDateLawMean

#daily rate
byDateLawMean%>%ggplot()+
  geom_line(aes(DateStart,count,color=Level))+
  geom_line(aes(DateStart,mon_mean,group=Level))+
  ggtitle("Daily Crime Frequency since 2000 with 30-day running mean")+
  labs(x="Date",y="Frequency")+theme(legend.title=element_blank())+geom_line(aes(DateStart,count*0+1150))

#Top 9 daily rate falls on Jan 1.
byDateLawMean%>%arrange(dplyr::desc(count))%>%filter(count>=count[9])%>%
  mutate(DateStart=as.factor(DateStart))%>%
  ggplot(aes(forcats::fct_reorder(DateStart, count),count))+geom_bar(stat="identity")+coord_flip()+ylab("Top 9 Daily Crime Frequency")+xlab("Date")
```

* The time series of crime frequency is decreasing over the years, consistent with shown in the cleveland dot plots of total count by year.  
* There are obvious annual variation/cycle. 30-day running mean shows the cycle clearly.
* There are spikes in the misdemeanor category and also felony category before 2006. The top 9 dates with high frequency are shown in the barchart. They are on January 1 on almost each year from 2000-2016 except 2015 which is actually very close behind. When reported, cases tend to be rounded onto Jan. 1 as occurrence date.
\
\
```{r}
#frequency by month
df_Date%>%mutate(Month=as.character(month(DateStart)))%>%group_by(Month,Level)%>%dplyr::summarise(CntByMon=n())->byDateLaw_mon

byDateLaw_mon%>%mutate(Days=rep(31,3))%>%mutate(Days=ifelse(Month=="2",28,Days))%>%mutate(Days=ifelse(Month %in% c("4","6","9","11"),30,Days))->byDateLaw_mon
byDateLaw_mon%>%ggplot(aes(fct_relevel(Month,"10","11","12",after=9),CntByMon/Days))+geom_bar(stat="identity")+coord_flip()+ylab("Crime Frequency (Monthly Mean)")+facet_wrap(~Level,scales="free_x")+xlab("Month")->p1
```

```{r}
#frequency by day
df_Date%>%mutate(Day=as.factor(format(DateStart,"%d")))%>%group_by(Day,Level)%>%dplyr::summarise(CntByDay=n())->byDateLaw_day

#Day1-28 has the same total cnts=11yrs*12cnts/yr
#Day 29 cnts=11yrs*11cnts/yr+3cnts (leap yrs)
#Day 30 cnts=11*11; Day 31 cnts=7*11
byDateLaw_day%>%mutate(cnts=rep(12*11,3))%>%mutate(cnts=ifelse(Day=="29",11*11+3,cnts))%>%mutate(cnts=ifelse(Day=="30",11*11,cnts))%>%mutate(cnts=ifelse(Day=="31",7*11,cnts))->byDateLaw_day

byDateLaw_day%>%ggplot(aes(Day,CntByDay/cnts))+geom_bar(stat="identity")+coord_flip()+ylab("Crime Frequency (Daily Mean)")+facet_wrap(~Level,scales="free_x")+xlab("Day of Month")->p2
```


```{r}
#frequency by weekday
df_Date%>%mutate(Wkday=as.factor(weekdays(DateStart,abbreviate=TRUE)))%>%group_by(Wkday,Level)%>%dplyr::summarise(CntByWkday=n())->byDateLaw_wkday

byDateLaw_wkday%>%ggplot(aes(fct_relevel(Wkday,"Mon","Tue","Wed","Thu","Fri","Sat","Sun"),CntByWkday))+geom_bar(stat="identity")+coord_flip()+ylab("Crime Frequency")+facet_wrap(~Level,scales="free_x")+xlab("Day of Week")->p3
```

```{r}
#picking non-missing TimeStart
crime_df%>%filter(!is.na(TimeStart))%>%filter(DateStart>=as.Date("2006-01-01"))->df_FRTM

#Frequency by hour of day, combining hour 00 and hour 24 into hour 00
df_FRTM%>%mutate(Hour=as.factor(substr(TimeStart,1,2)))%>%group_by(Hour,Level)%>%dplyr::summarise(CntByHour=n())->byDateLaw_hour
byDateLaw_hour$Hour[byDateLaw_hour$Hour=="24"]<-"00"
byDateLaw_hour$Hour<-factor(byDateLaw_hour$Hour)

byDateLaw_hour%>%ggplot(aes(Hour,CntByHour))+geom_bar(stat="identity")+coord_flip()+ylab("Crime Frequency")+facet_wrap(~Level,scales="free_x")+xlab("Hour of Day")->p4
```

```{r fig.height=4,fig,width=6}
grid.arrange(p1,p2,p3,p4,nrow=2)
```


* Indeed by barcharting over the months,we see Jun.-Oct. is a high crime season.
* The spike in Janurary is consistent with the analysis above. 
* There seemed having a tendency of rounding every 5 day.
* Violation is low during weekends but same during weekdays.
* Felony and misdemeanor is high on Friday but low on Sunday nad Monday.
* There is obvious day cycle in the crime occurrence. Early morning has the least crime occurrence while later afternoon has the most crime occurrence.
\
\
```{r fig.height=4.7,fig.width=5.5}
#how the different crime types (OffenseDesc) associated with different places (a heatmap)
crime_df%>%
  select(ClassCode,PremDesc)%>%
  filter(!is.na(PremDesc))%>%
  group_by(ClassCode,PremDesc)%>%dplyr::summarise(count=n())%>%mutate(pct=count/sum(count))->byKYbyPREM

#merging to get OffenseDesc vs PremDesc correspondence
match_code_desc%>%mutate(ClassCode=as.factor(ClassCode))->match_code_desc
merge(byKYbyPREM, match_code_desc, by.x='ClassCode', by.y='ClassCode')->byKYbyPREM_match

byKYbyPREM_match%>%group_by(OffenseDesc)%>%dplyr::summarise(mean=mean(count),na.rm=TRUE)%>%arrange(dplyr::desc(mean))->desc_desc_cnt
byKYbyPREM_match%>%group_by(PremDesc)%>%dplyr::summarise(mean=mean(count),na.rm=TRUE)%>%arrange(dplyr::desc(mean))->PREM_desc_cnt

byKYbyPREM_match%>%
  ggplot(aes(fct_relevel(as.factor(OffenseDesc),as.character(desc_desc_cnt$OffenseDesc[sort(desc_desc_cnt$mean,index.return=TRUE,decreasing=TRUE)$ix])),
  fct_relevel(as.factor(PremDesc),as.character(PREM_desc_cnt$PremDesc[sort(PREM_desc_cnt$mean,index.return=TRUE,decreasing=TRUE)$ix])),fill=pct))+scale_fill_gradientn(colors=c("red","orange","yellow","green","blue","violet"),na.value="black")+
  scale_x_discrete(label=function(x) abbreviate(x, minlength=20))+coord_flip()+geom_tile(color="white",size=0.25)+
  theme(axis.text.x = element_text(size=3,angle = 45, hjust =1), axis.text.y=element_text(size=4),  legend.position="top",legend.text=element_text(size=6,hjust=0.5),legend.title=element_text(size=8),
        legend.key = element_rect(size = 0.5),legend.key.size = unit(1, 'lines'))+ylab("Premises")+xlab("OffenseDesc")
```


* Doesn't seem having association between crime types and premises.
\
\
```{r fig.height=4.5,fig.width=4}
#how the different crime types associated with time using heatmap
crime_df%>%
  select(ClassCode,TimeStart)%>%
  filter(!is.na(TimeStart))%>%
  mutate(ClassCode=as.factor(ClassCode))%>%
  mutate(Hour=as.factor(substr(TimeStart,1,2)))%>%
  group_by(ClassCode,Hour)%>%dplyr::summarise(count=n())%>%mutate(pct=count/sum(count))->byKYbyFRTM
#combining hour 00 and hour 24 into hour 00
byKYbyFRTM$Hour[byKYbyFRTM$Hour=="24"]<-"00"
byKYbyFRTM$Hour<-factor(byKYbyFRTM$Hour)

#merging to get OffenseDesc vs TimeStart correspondence
merge(byKYbyFRTM, match_code_desc, by.x='ClassCode', by.y='ClassCode')->byKYbyFRTM_match

byKYbyFRTM_match%>%group_by(OffenseDesc)%>%dplyr::summarise(mean=mean(count),na.rm=TRUE)->desc2_desc_cnt
byKYbyFRTM_match%>%group_by(Hour)%>%dplyr::summarise(mean=mean(count),na.rm=TRUE)->Hour_desc_cnt

byKYbyFRTM_match%>%ggplot(aes(
  fct_relevel(as.factor(OffenseDesc),as.character(desc2_desc_cnt$OffenseDesc[sort(desc2_desc_cnt$mean,index.return=TRUE,decreasing=TRUE)$ix])),
  Hour,fill=pct))+scale_fill_gradientn(colors=c("red","orange","yellow","green","blue","violet"),na.value="black")+
  scale_x_discrete(label=function(x) abbreviate(x, minlength=20))+coord_flip()+geom_tile(color="white",size=0.25)+
  theme(axis.text.x = element_text(size=5, hjust = 0.5),axis.text.y=element_text(size=4),legend.position="bottom",
        legend.text=element_text(size=6,hjust=0.5),legend.title=element_text(size=8),legend.key = element_rect(size = 0.5),legend.key.size = unit(1, 'lines'))+ylab("Hour")+xlab("OffenseDesc")
```


* Do we see any association between time and certain crime? Do see some high density around middle up right area, which is consistent with the barcharting daily cycle.
\
\
```{r fig.height=4.5}
#matching Pct with Boro
crime_df %>% select(Level,Pct)%>%group_by(Level,Pct)%>%
  drop_na()%>%dplyr::summarize(count = n())%>%ungroup()->df_pct
merge(df_pct,match_pct_boro,by.x="Pct",by.y="Pct")->df_pbl
df_pbl%>%mutate(Pct=as.factor(Pct))->df_pbl

df_pbl%>%ggplot(aes(reorder(Pct, count), count,fill=Boro)) + geom_bar(stat = "identity") + xlab("Precint Number") + ggtitle("Incidents by Precinct") + coord_flip()+scale_fill_manual(values = c("blue", "orange","green","red","yellow"))+theme(axis.text.x = element_text(size=5, hjust = 0.5),axis.text.y=element_text(size=4),legend.position=c(0.6,0.2),
        legend.text=element_text(size=6,hjust=0.5),legend.title=element_text(size=8),legend.key = element_rect(size = 0.5),legend.key.size = unit(1, 'lines'))->p5
df_pbl%>%ggplot(aes(reorder(Pct, count), count,fill=Level)) + geom_bar(stat = "identity") + xlab("Precint Number") + ggtitle("Incidents by Precinct") + coord_flip()+scale_fill_manual(values = c("blue", "green","red"))+theme(axis.text.x = element_text(size=5, hjust = 0.5),axis.text.y=element_text(size=4),legend.position=c(0.6,0.2),
        legend.text=element_text(size=6,hjust=0.5),legend.title=element_text(size=8),legend.key = element_rect(size = 0.5),legend.key.size = unit(1, 'lines'))->p6
grid.arrange(p5,p6,nrow=1)
```

* Crime frequency by Pct with either borough name colored or crime Level colored. 
\
\
```{r}
crime_df%>%filter(!is.na(ParkName))->df_pk
df_pk%>%select(Level)%>%group_by(Level)%>%dplyr::summarise(count=n())%>%mutate(RelFreq = count/sum(count))%>%ggplot(aes(Level,RelFreq))+geom_bar(stat="identity")+
  coord_flip()+ylab("Level of Offense")+xlab("Relative Frequency")
```
\
\
* ~12538 cases recorded as occurred in parks/playground or greenspaces. The crime level distribution share the same pattern as the overall data. 
\
\